{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing - Improvement 2\n",
    "This section focuses on cleaning, transforming, and preparing the e-commerce dataset for analysis and modeling in the second improvement of user-based fairness addition to FCPO in e-commerce domain.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import csv\n",
    "import time\n",
    "import copy\n",
    "import ast  \n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import coo_matrix\n",
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataPreprocessorEcommerce():\n",
    "    def __init__(self, datapath, itempath):\n",
    "        '''\n",
    "        Load data from the E commerce Purchase Dataset\n",
    "        List the users and the items\n",
    "        List all the users historic\n",
    "        '''\n",
    "        self.data  = self.load_data(datapath, itempath)\n",
    "        print(\"Og Data\")\n",
    "        print(self.og_data.head())\n",
    "        print(\"Data\")\n",
    "        print(self.data.head())\n",
    "        \n",
    "        self.userId = np.array(self.data['userId'].values.tolist())\n",
    "        self.itemId = np.array(self.data['itemId'].values.tolist())\n",
    "        \n",
    "        # Subtract 501 from each element in self.itemId\n",
    "        self.itemId = self.itemId - 501\n",
    "        \n",
    "        self.data['userId'] = list(self.userId)\n",
    "        self.data['itemId'] = list(self.itemId)\n",
    "        \n",
    "        print(\"after list\")\n",
    "        print(self.data.head())\n",
    "        \n",
    "        self.users = self.data['userId'].unique()   #list of all users\n",
    "        self.items = self.data['itemId'].unique()   #list of all items\n",
    "        self.nb_user = len(self.users)\n",
    "        self.nb_item = len(self.items)\n",
    "        print('total num of users:',self.nb_user)\n",
    "        print('total num of items:',self.nb_item)\n",
    "        \n",
    "        #a list contains the rating history of each user\n",
    "        self.histo = self.gen_histo()\n",
    "\n",
    "\n",
    "    def load_data(self, dataname, datapath):\n",
    "        '''\n",
    "        Load the data\n",
    "        '''\n",
    "        # Read the CSV file without specifying column names or dtypes\n",
    "        data = pd.read_csv(datapath)\n",
    "        self.og_data = copy.deepcopy(data)#store original dataset\n",
    "        \n",
    "        # Define the desired column names and their corresponding dtypes\n",
    "        desired_columns = ['customer_id', 'product_category', 'time_on_site [Minutes]', 'clicks_in_site', 'date']\n",
    "        dtypes = {\n",
    "            'customer_id': np.int32,\n",
    "            'product_category': np.int32,\n",
    "            'time_on_site [Minutes]': np.float64,\n",
    "            'clicks_in_site': np.float64,\n",
    "        }\n",
    "\n",
    "        # Filter the DataFrame to keep only the desired columns\n",
    "        data = data[desired_columns]\n",
    "        #print(data.head())\n",
    "\n",
    "        # Rename the columns (if needed) and set their dtypes\n",
    "        data = data.astype(dtypes)\n",
    "        #print(data.head())\n",
    "\n",
    "        # Parse the date column and ensure dayfirst is True\n",
    "        data['date'] = pd.to_datetime(data['date'], dayfirst=True)\n",
    "        \n",
    "        # Find the minimum date\n",
    "        min_date = data['date'].min()\n",
    "\n",
    "        # Calculate the difference in days\n",
    "        data['days_since_min'] = (data['date'] - min_date).dt.days\n",
    "        #print(data.head())\n",
    "        # Rename columns to desired names\n",
    "        data.rename(columns={\n",
    "            'customer_id': 'userId',\n",
    "            'product_category': 'itemId',\n",
    "            'time_on_site [Minutes]': 'time_on_site',\n",
    "            'clicks_in_site': 'clicks_in_site',\n",
    "            'days_since_min': 'timestamp'\n",
    "        }, inplace=True)\n",
    "        #print(data.head())\n",
    "        \n",
    "        # Calculate 'rating' as clicks_in_site / time_on_site where both are non-null\n",
    "        data['rating'] = np.where(data['clicks_in_site'].notna() & data['time_on_site'].notna(),\n",
    "                                data['clicks_in_site'] / data['time_on_site'],\n",
    "                                np.nan)\n",
    "        \n",
    "        # Drop the individual time_on_site and clicks_in_site columns\n",
    "        data.drop(columns=['time_on_site', 'clicks_in_site','date'], inplace=True)\n",
    "\n",
    "        return data\n",
    "\n",
    "    def read_file(self, filename, isTrain=True):\n",
    "        df = pd.read_csv(filename)\n",
    "        user = df['user'].values.tolist()\n",
    "        state = [ast.literal_eval(i) for i in df['state'].values.tolist()]\n",
    "        if isTrain:\n",
    "            state_reward = [ast.literal_eval(i) for i in df['state_reward'].values.tolist()]\n",
    "        history = [np.array(ast.literal_eval(i)) for i in df['history'].values.tolist()]\n",
    "        rewards = [ast.literal_eval(i) for i in df['rewards'].values.tolist()]\n",
    "        data = pd.DataFrame ()\n",
    "        data['user'] = user\n",
    "        data['state'] = state\n",
    "        if isTrain:\n",
    "            data['state_reward'] = state_reward\n",
    "        data['history'] = history\n",
    "        data['rewards'] = rewards\n",
    "        return data\n",
    "    \n",
    "    def gen_histo(self):\n",
    "        '''\n",
    "        Group all rates given by users and store them from older to most recent.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        result :    List(DataFrame)\n",
    "        List of the historic for each user\n",
    "        '''\n",
    "        print('start generating user history...')\n",
    "        historic_users = []\n",
    "        for i, u in tqdm(enumerate(self.users)):\n",
    "            temp = self.data[self.data['userId'] == u]\n",
    "            temp = temp.sort_values ('timestamp').reset_index ()\n",
    "            temp.drop ('index', axis = 1, inplace = True)\n",
    "            historic_users.append (temp)\n",
    "        return historic_users\n",
    "\n",
    "\n",
    "    def sample_histo_v6(self, user_histo, nb_states, nb_actions, pivot_rating=0):\n",
    "        n = len(user_histo)\n",
    "        states = []\n",
    "        actions = []\n",
    "        rewards = []\n",
    "        states_prime = []\n",
    "        done = []\n",
    "        state_len = nb_states\n",
    "        action_len = nb_actions\n",
    "        \n",
    "        item_list = user_histo['itemId'].values.tolist()\n",
    "        click_list = user_histo['rating'].values.tolist()\n",
    "        \n",
    "        initial_state = []\n",
    "        initial_end = 0\n",
    "        for i in range(len(item_list)):\n",
    "            if click_list[i] > pivot_rating and len(initial_state) < state_len:\n",
    "                initial_state.append(item_list[i])\n",
    "                initial_end = i\n",
    "        if len(initial_state) == state_len and (initial_end + action_len <= len(item_list)):\n",
    "            current_state = copy.copy(initial_state)\n",
    "            for i in range(initial_end+1,len(item_list),action_len):\n",
    "                if i+action_len <= len(item_list):\n",
    "                    actions.append(item_list[i:i+action_len])\n",
    "                    rewards.append(click_list[i:i+action_len])\n",
    "                    states.append(copy.copy(current_state))\n",
    "                    done.append(False)\n",
    "                    for j in range(i,i+action_len):\n",
    "                        if click_list[j] > pivot_rating:\n",
    "                            current_state.append(item_list[j])\n",
    "                            del current_state[0]\n",
    "                    states_prime.append(copy.copy(current_state))\n",
    "        if len(done) > 0:\n",
    "            done[-1] = True\n",
    "        return states, actions, rewards, states_prime, done\n",
    "\n",
    "    def sample_histo_v5(self, user_histo, nb_states, pivot_rating):\n",
    "        prop_histo = user_histo[user_histo['rating'] >= pivot_rating]\n",
    "        if len(prop_histo) > nb_states:\n",
    "            user = user_histo['userId'][0]\n",
    "            initial_state =  prop_histo[0:nb_states]['itemId'].values.tolist()\n",
    "            initial_rewards = prop_histo[0:nb_states]['rating'].values.tolist()\n",
    "            user_history =  prop_histo[nb_states:]['itemId'].values.tolist()\n",
    "            rewards = prop_histo[nb_states:]['rating'].values.tolist()\n",
    "        return user, initial_state, initial_rewards, user_history, rewards\n",
    "    \n",
    "            \n",
    "            \n",
    "    def get_orginal_data(self, train_filename, test_filename):\n",
    "        self.data.to_csv('/kaggle/working/train_data_org.csv', index=False, header=None)\n",
    "        print('done!')\n",
    "        \n",
    "        #write the cost embedding \n",
    "        items = self.data['itemId'].to_list()\n",
    "        items = np.array(items)\n",
    "        idx, nb = np.unique(items, return_counts=True)\n",
    "        # idx,nb\n",
    "        #print(idx)\n",
    "        #print(nb)\n",
    "        pivot_point = 0\n",
    "        while np.sum(nb>pivot_point)/self.nb_item >= 0.2:\n",
    "            pivot_point += 1\n",
    "        print('pivot point:', pivot_point)\n",
    "\n",
    "        cost_indicator = np.zeros(self.nb_item)\n",
    "        item_exposure = np.zeros(self.nb_item)\n",
    "        for i in range(len(nb)):\n",
    "            item_exposure[idx[i]] = nb[i]\n",
    "            if nb[i] > pivot_point:\n",
    "                cost_indicator[idx[i]] += 1\n",
    "        np.save('/kaggle/working/item_cost_indicator_28_e_commerce.npy', cost_indicator)\n",
    "        print(cost_indicator.shape)\n",
    "        print(cost_indicator)\n",
    "        np.save('/kaggle/working/item_exposure_28_e_commerce.npy', item_exposure)\n",
    "        \n",
    "                \n",
    "                    \n",
    "    def generate_pmf(self, output_path_item, output_path_user):\n",
    "        # Convert to a sparse matrix\n",
    "        user_ids = self.data['userId']\n",
    "        item_ids = self.data['itemId']\n",
    "        ratings = self.data['rating']\n",
    "\n",
    "        # Adjust indices for 0-based indexing if necessary\n",
    "        user_ids -= user_ids.min()\n",
    "        item_ids -= item_ids.min()\n",
    "        \n",
    "        # Map user and item IDs to a 0-based index for the sparse matrix\n",
    "        unique_users, user_index = np.unique(user_ids, return_inverse=True)\n",
    "        unique_items, item_index = np.unique(item_ids, return_inverse=True)\n",
    "\n",
    "        # Create the sparse user-item interaction matrix\n",
    "        num_users = len(unique_users)\n",
    "        num_items = len(unique_items)\n",
    "        user_item_matrix = coo_matrix((ratings, (user_index, item_index)), shape=(num_users, num_items))\n",
    "\n",
    "        # Apply Truncated SVD to approximate PMF\n",
    "        embedding_dim = 10\n",
    "        svd = TruncatedSVD(n_components=embedding_dim)\n",
    "\n",
    "        # Get user and item embeddings\n",
    "        user_embeddings = svd.fit_transform(user_item_matrix)    # User embeddings\n",
    "        item_embeddings = svd.components_.T                      # Item embeddings\n",
    "\n",
    "        # Convert embeddings to DataFrames for easy export\n",
    " \n",
    "        item_embedding_df = pd.DataFrame(item_embeddings)\n",
    "        user_embedding_df = pd.DataFrame(user_embeddings)\n",
    "\n",
    "        # Save embeddings to CSV\n",
    "        item_embedding_df.to_csv(output_path_item)\n",
    "        user_embedding_df.to_csv(output_path_user)\n",
    "\n",
    "        print(f\"Item embeddings saved to {output_path_item}\")\n",
    "        print(item_embedding_df.shape)\n",
    "        print(item_embedding_df)\n",
    "        print(f\"User embeddings saved to {output_path_user}\")\n",
    "        print(user_embedding_df.shape)\n",
    "        print(user_embedding_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Og Data\n",
      "         date  customer_id  product_category payment_method  value [USD]  \\\n",
      "0  20/11/2018        37077               505         credit        49.53   \n",
      "1  20/11/2018        59173               509         paypal        50.61   \n",
      "2  20/11/2018        41066               507         credit        85.99   \n",
      "3  20/11/2018        50741               506         credit        34.60   \n",
      "4  20/11/2018        53639               515         paypal       266.27   \n",
      "\n",
      "   time_on_site [Minutes]  clicks_in_site  Unnamed: 7  \n",
      "0                    12.0               8         NaN  \n",
      "1                    25.9               8         NaN  \n",
      "2                    34.9              11         NaN  \n",
      "3                    16.5               9         NaN  \n",
      "4                    43.1              30         NaN  \n",
      "Data\n",
      "   userId  itemId  timestamp    rating\n",
      "0   37077     505          0  0.666667\n",
      "1   59173     509          0  0.308880\n",
      "2   41066     507          0  0.315186\n",
      "3   50741     506          0  0.545455\n",
      "4   53639     515          0  0.696056\n",
      "after list\n",
      "   userId  itemId  timestamp    rating\n",
      "0   37077       4          0  0.666667\n",
      "1   59173       8          0  0.308880\n",
      "2   41066       6          0  0.315186\n",
      "3   50741       5          0  0.545455\n",
      "4   53639      14          0  0.696056\n",
      "total num of users: 19774\n",
      "total num of items: 15\n",
      "start generating user history...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19774it [00:20, 978.29it/s] \n"
     ]
    }
   ],
   "source": [
    "datapath = '/kaggle/input/e-commerce-purchase-dataset/purchase_data_exe.csv'\n",
    "#datapath = './purchase_data_exe.csv'\n",
    "# print(datapath)\n",
    "dg = DataPreprocessorEcommerce('e_commerce', datapath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "unique_items = np.unique(dg.itemId)\n",
    "for x in unique_items:\n",
    "    print(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>itemId</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39783</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39783</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.010657</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  itemId  timestamp    rating\n",
       "0   39783       0          0  0.714286\n",
       "1   39783       1          8  0.010657"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dg.histo[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filename = '/kaggle/working/train_data_e_commerce.csv'\n",
    "test_filename = '/kaggle/working/test_data_e_commerce.csv'\n",
    "validation_filename = '/kaggle/working/validation_data_e_commerce.csv'\n",
    "train_test_ratio=0.8\n",
    "pivot_rating=0\n",
    "nb_states=1\n",
    "nb_history = 2\n",
    "nb_actions=1\n",
    "users = []\n",
    "initial_states = []\n",
    "initial_rewards = []\n",
    "user_histories = []\n",
    "rewards = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "660"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_cases = 0\n",
    "for user_histo in dg.histo:\n",
    "    try:\n",
    "        prop_histo = user_histo[user_histo['rating'] >= pivot_rating]\n",
    "        if len(prop_histo) >= nb_states:\n",
    "            user = user_histo['userId'][0]\n",
    "            init_state =  prop_histo[0:nb_states]['itemId'].values.tolist()\n",
    "            init_r = prop_histo[0:nb_states]['rating'].values.tolist()\n",
    "            u_history =  prop_histo[nb_states:]['itemId'].values.tolist()\n",
    "            r = prop_histo[nb_states:]['rating'].values.tolist()\n",
    "            #user, init_state, init_r, u_history, r = dg.sample_histo_v6(user_histo, nb_states, pivot_rating)\n",
    "            # Print variables with a tab before each output\n",
    "            #print(f\"\\tuser: {user}\")\n",
    "            #print(f\"\\tinit_state: {init_state}\")\n",
    "            #print(f\"\\tinit_r: {init_r}\")\n",
    "            #print(f\"\\tu_history: {u_history}\")\n",
    "            if len(u_history) >= nb_history:\n",
    "                #print(f\"\\tr: {r}\")\n",
    "                #print(f\"\\tu_history: {u_history}\")\n",
    "                nb_cases += 1\n",
    "                users.append(user)\n",
    "                initial_states.append(init_state)\n",
    "                initial_rewards.append(init_r)\n",
    "                user_histories.append(u_history)\n",
    "                rewards.append(r)\n",
    "        continue\n",
    "    except:\n",
    "        continue\n",
    "        \n",
    "#print(f\"\\tuser: {users}\")\n",
    "#print(f\"\\tinit_state: {initial_states}\")\n",
    "#print(f\"\\tinit_r: {initial_rewards}\")\n",
    "#print(f\"\\tu_history: {user_histories}\")\n",
    "#print(f\"\\tr: {rewards}\") \n",
    "nb_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_split = pd.DataFrame()\n",
    "data_to_split['user'] = users\n",
    "data_to_split['state'] = initial_states\n",
    "data_to_split['state_reward'] = initial_rewards\n",
    "data_to_split['history'] = user_histories\n",
    "data_to_split['rewards'] = rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "train_data, test_data = train_test_split(\n",
    "        data_to_split, train_size=train_test_ratio, random_state=42\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "(528, 5)\n",
      "      user state           state_reward     history  \\\n",
      "18   38300  [12]  [0.37037037037037035]      [3, 0]   \n",
      "363  27752   [5]    [1.417624521072797]  [8, 5, 10]   \n",
      "597  42041   [4]   [0.8148148148148148]  [0, 2, 14]   \n",
      "541  42523   [8]   [0.8421052631578947]     [10, 8]   \n",
      "61   26766  [13]  [0.26022304832713755]     [14, 4]   \n",
      "..     ...   ...                    ...         ...   \n",
      "71   14183   [2]   [0.4225352112676057]   [4, 9, 9]   \n",
      "106  16332  [14]  [0.18324607329842932]  [2, 10, 3]   \n",
      "270  17239  [10]   [1.1188811188811187]    [12, 11]   \n",
      "435  56299   [4]   [1.0738255033557047]     [12, 1]   \n",
      "102  46781   [0]    [2.258064516129032]      [1, 3]   \n",
      "\n",
      "                                               rewards  \n",
      "18            [0.8588957055214723, 1.7777777777777777]  \n",
      "363     [0.75, 0.5084745762711864, 1.0294117647058825]  \n",
      "597  [4.509803921568627, 0.7894736842105263, 0.2550...  \n",
      "541          [1.1475409836065573, 0.31088082901554404]  \n",
      "61                        [1.5384615384615383, 0.3125]  \n",
      "..                                                 ...  \n",
      "71   [0.3493449781659389, 0.23880597014925373, 0.15...  \n",
      "106  [0.5232558139534884, 0.6962025316455696, 0.012...  \n",
      "270           [0.2682926829268293, 0.3547066848567531]  \n",
      "435                          [1.4736842105263157, 1.0]  \n",
      "102           [1.3333333333333333, 0.5263157894736842]  \n",
      "\n",
      "[528 rows x 5 columns]\n",
      "test\n",
      "(132, 5)\n",
      "      user state           state_reward    history  \\\n",
      "629  47745   [6]   [1.6666666666666665]     [4, 6]   \n",
      "499  38636   [1]   [0.9865470852017937]  [0, 5, 8]   \n",
      "135  46677  [10]   [1.0619469026548671]     [5, 4]   \n",
      "480  20377   [9]  [0.08771929824561403]    [4, 14]   \n",
      "90   34287  [14]   [0.7954545454545454]    [11, 6]   \n",
      "..     ...   ...                    ...        ...   \n",
      "77   56392  [14]   [0.5305039787798408]    [10, 4]   \n",
      "530  11050   [6]   [1.5454545454545454]  [9, 1, 0]   \n",
      "407  48833   [9]   [1.3114754098360657]    [10, 2]   \n",
      "234  59770  [11]   [0.5691056910569106]     [0, 9]   \n",
      "579  12085   [4]   [0.4023845007451565]  [6, 5, 3]   \n",
      "\n",
      "                                               rewards  \n",
      "629           [0.9677419354838709, 3.4615384615384612]  \n",
      "499  [0.37190082644628103, 0.2349869451697128, 0.49...  \n",
      "135          [0.6962025316455696, 0.13761467889908255]  \n",
      "480          [0.5389221556886228, 0.49751243781094523]  \n",
      "90            [0.5836575875486382, 0.0213903743315508]  \n",
      "..                                                 ...  \n",
      "77            [0.29850746268656714, 1.206896551724138]  \n",
      "530  [2.8634361233480177, 1.0566037735849056, 0.032...  \n",
      "407            [0.140117994100295, 0.3262642740619902]  \n",
      "234           [0.6206896551724138, 0.9090909090909091]  \n",
      "579  [0.2835820895522388, 0.20356234096692113, 0.15...  \n",
      "\n",
      "[132 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "print(\"train\")\n",
    "print(train_data.shape)\n",
    "print(train_data)\n",
    "print(\"test\")\n",
    "print(test_data.shape)\n",
    "print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(len(train_data_rewards.shape[1]),len(test_data_rewards.shape[1]))\n",
    "if train_filename != None and test_filename != None: \n",
    "    train_data.to_csv(train_filename, index=False)\n",
    "    test_data.to_csv(validation_filename, index=False)\n",
    "    test_data = test_data.drop(columns=['state_reward'])\n",
    "    test_data.to_csv(test_filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>itemId</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37077</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>59173</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.308880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41066</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.315186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50741</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.545455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>53639</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0.696056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24994</th>\n",
       "      <td>33699</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>0.155211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>38652</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.180328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>30222</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>0.852273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>30183</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>1.305842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>46662</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>0.127119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24999 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       userId  itemId  timestamp    rating\n",
       "0       37077       4          0  0.666667\n",
       "1       59173       8          0  0.308880\n",
       "2       41066       6          0  0.315186\n",
       "3       50741       5          0  0.545455\n",
       "4       53639      14          0  0.696056\n",
       "...       ...     ...        ...       ...\n",
       "24994   33699      12          9  0.155211\n",
       "24995   38652       0          9  0.180328\n",
       "24996   30222       3          9  0.852273\n",
       "24997   30183       6          9  1.305842\n",
       "24998   46662       4          9  0.127119\n",
       "\n",
       "[24999 rows x 4 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dg.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique items in customerId: 19774\n",
      "Number of unique items in product_category: 15\n"
     ]
    }
   ],
   "source": [
    "num_unique_customers = dg.og_data['customer_id'].nunique()\n",
    "print(\"Number of unique items in customerId:\", num_unique_customers)\n",
    "num_unique_product = dg.og_data['product_category'].nunique()\n",
    "print(\"Number of unique items in product_category:\", num_unique_product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>itemId</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26767</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0.689655</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  itemId  timestamp    rating\n",
       "0   26767      13          0  0.689655"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dg.histo[6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate item cost indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pivot point: 1680\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/kaggle/working/item_cost_indicator_28_e_commerce.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m         cost_indicator[idx[i]] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     20\u001b[0m cost_indicator_array \u001b[38;5;241m=\u001b[39m  cost_indicator\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[0;32m---> 21\u001b[0m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msavetxt\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/kaggle/working/item_cost_indicator_28_e_commerce.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcost_indicator_array\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelimiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m,\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m#print(cost_indicator_array.shape)\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(cost_indicator_array)\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36msavetxt\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/py3.8/lib/python3.8/site-packages/numpy/lib/npyio.py:1541\u001b[0m, in \u001b[0;36msavetxt\u001b[0;34m(fname, X, fmt, delimiter, newline, header, footer, comments, encoding)\u001b[0m\n\u001b[1;32m   1538\u001b[0m     fname \u001b[38;5;241m=\u001b[39m os_fspath(fname)\n\u001b[1;32m   1539\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_string_like(fname):\n\u001b[1;32m   1540\u001b[0m     \u001b[38;5;66;03m# datasource doesn't support creating a new file ...\u001b[39;00m\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m   1542\u001b[0m     fh \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlib\u001b[38;5;241m.\u001b[39m_datasource\u001b[38;5;241m.\u001b[39mopen(fname, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwt\u001b[39m\u001b[38;5;124m'\u001b[39m, encoding\u001b[38;5;241m=\u001b[39mencoding)\n\u001b[1;32m   1543\u001b[0m     own_fh \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/working/item_cost_indicator_28_e_commerce.csv'"
     ]
    }
   ],
   "source": [
    "#write the cost embedding \n",
    "items = dg.data['itemId'].to_list()\n",
    "items = np.array(items)\n",
    "idx, nb = np.unique(items, return_counts=True)\n",
    "# idx,nb\n",
    "#print(idx)\n",
    "#print(nb)\n",
    "pivot_point = 0\n",
    "while np.sum(nb>pivot_point)/dg.nb_item >= 0.2:\n",
    "    pivot_point += 1\n",
    "print('pivot point:', pivot_point)\n",
    "\n",
    "cost_indicator = np.zeros(dg.nb_item)\n",
    "item_exposure = np.zeros(dg.nb_item)\n",
    "for i in range(len(nb)):\n",
    "    item_exposure[idx[i]] = nb[i]\n",
    "    if nb[i] > pivot_point:\n",
    "        cost_indicator[idx[i]] += 1\n",
    "        \n",
    "cost_indicator_array =  cost_indicator.flatten()\n",
    "np.savetxt('/kaggle/working/item_cost_indicator_28_e_commerce.csv', cost_indicator_array, delimiter=\",\")\n",
    "\n",
    "#print(cost_indicator_array.shape)\n",
    "print(cost_indicator_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate user cost indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "        Calculate and add user_indicator based on interaction frequency.\n",
    "        Users with interaction frequency in the bottom 20% are marked as sensitive.\n",
    "\"\"\"\n",
    "# Calculate the total interaction frequency for each user (sum of ratings per user)\n",
    "user_interaction = dg.data.groupby('userId')['rating'].sum()\n",
    "\n",
    "# Define the threshold for the bottom 20% to identify low-interaction users\n",
    "sensitivity_threshold = np.percentile(user_interaction, 20)\n",
    "\n",
    "# Create user_indicator where 1 represents sensitive (low interaction) users and 0 otherwise\n",
    "user_indicator = (user_interaction <= sensitivity_threshold).astype(int)\n",
    "\n",
    "# Map the user_indicator back to the main DataFrame\n",
    "\n",
    "print(\"User indicator based on low interaction frequency has been added to the data.\")\n",
    "        \n",
    "np.save('/kaggle/working/item_user_indicator_28_e_commerce.npy', user_indicator)\n",
    "#print(cost_indicator_array.shape)\n",
    "print(user_indicator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_indicator.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate pmf embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path_item = \"/kaggle/working/pmf_item_embed_e_commerce.npy\"\n",
    "output_path_user = \"/kaggle/working/pmf_user_embed_e_commerce.npy\"\n",
    "dg.generate_pmf(output_path_item,output_path_user)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 450405,
     "sourceId": 851167,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
